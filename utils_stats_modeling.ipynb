{"cells":[{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn import metrics\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom sklearn.metrics import mean_squared_error, median_absolute_error, mean_absolute_error, r2_score"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e266fb0d-4a8b-4aa6-baf1-e8c393ebc32a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def evaluation_metrics(y_test, predictions, model_name=None):\n    \n    mae = mean_absolute_error(y_test, predictions)\n    mdae = median_absolute_error(y_test, predictions)\n    mse = mean_squared_error(y_test, predictions)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(y_test, predictions)\n    error_ratio = 100*mae/np.mean(y_test)\n    \n    print('====================================================')\n    if model_name is not None:\n        print('    Evaluation of', model_name, 'Model')\n        print('****************************************************')\n    # Evaluating the model using MAE Evaluation Metric\n    print('Mean Absolute Error = ', mae)\n\n    # Evaluating the model using Median Absolute Error Evaluation Metric\n    print('Median Absolute Error = ', mdae)\n\n    # Evaluating the model using MSE Evaluation Metric\n    print('Mean Squared Error = ', mse)\n\n    # Evaluating the model using RMSE Evaluation Metric\n    print('Root Mean Squared Error = ', rmse)\n\n    # Evaluating the model using RÂ² Evaluation Metric\n    print('R2 Score = ', r2)\n\n    # Error percentage\n    print('MAE to Mean Ratio Percentage=', error_ratio, '%')\n    print('****************************************************')\n    print('====================================================')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5f8df67-0ee6-4584-8270-ebf0bfbe582b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def dickey_fuller(ts, plot_log, print_output):\n    \n    '''\n    Tests a time series for stationarity using the Dickey Fuller test.\n    Inputs:\n        - ts: time series for testing\n        - plot_log: boolean to log transform the time series\n        - print_output: boolean to print the results or not\n    Returns:\n        - Boolean for stationary or not\n        - P value from the test\n    '''\n    \n    if plot_log:\n        dftest = adfuller(np.log(ts))\n    else:\n        dftest = adfuller(ts)\n\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n        \n    if dfoutput['p-value'] > 0.05:\n        if print_output:\n            print(f\"Data is not stationary. P-value of {dfoutput['p-value']:.4f}\")\n        stationary = False\n    else:\n        if print_output:\n            print(f\"Data is stationary. P-value of {dfoutput['p-value']:.4f}\")\n        stationary = True\n        \n    return stationary, dfoutput['p-value']\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74959b64-7c0f-4f55-9314-97c2497c99c5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ba1975c5-ed77-41a0-bed0-d5bca40a6e51"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def run_model(results, df_preds_, neighborhood, ts, order, seasonal_order, logged):\n    \n    '''\n    This runs a SARIMAX model with the specified order for a given neighborhood\n    '''\n    \n    train = ts[ts['future'] == 0]\n    test = ts[ts['future'] == 1]\n\n    \n    if logged:\n        sari_model = SARIMAX(train['ride_count_log'], order=order, seasonal_order=seasonal_order).fit(maxiter=1000, disp=False)\n    else:\n        sari_model = SARIMAX(train['ride_count'], order=order, seasonal_order=seasonal_order).fit(maxiter=1000, disp=False)\n    \n    # Add preds to predictions DataFrame\n    preds = sari_model.forecast(steps = len(test))\n    if logged:\n        df_preds_.loc[:,neighborhood] = np.exp(preds)\n    else:\n        df_preds_.loc[:,neighborhood] = preds\n    \n    # Retrieve metrics\n    if logged:\n        model_results = report_metrics(test['ride_count_log'], preds, False)\n    else:\n        model_results = report_metrics(test['ride_count'], preds, False)\n    \n    # Calculate actual vs. predicted rides for 2021\n    actual_rides_2021 = ts[ts.index > '12/31/2020']['ride_count'].sum()\n    pred_rides_2021 = df_preds_[df_preds_.index > '12/31/2020'][neighborhood].sum()\n    \n    ride_delta = np.abs(pred_rides_2021 - actual_rides_2021)\n    \n    # Add results to results dataframe\n    results.loc[neighborhood, 'model'] = sari_model\n    results.loc[neighborhood, 'order'] = order\n    results.loc[neighborhood, 'seasonal_order'] = seasonal_order\n    results.loc[neighborhood, 'explained_variance'] = model_results[0]\n    results.loc[neighborhood, 'MAE'] = model_results[1]\n    results.loc[neighborhood, 'MSE'] = model_results[2]\n    results.loc[neighborhood, 'R2'] = model_results[3]\n    results.loc[neighborhood, '2021_actual'] = actual_rides_2021\n    results.loc[neighborhood, '2021_predicted'] = pred_rides_2021\n    results.loc[neighborhood, 'delta'] = ride_delta\n    \n    return results, df_preds_"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7302b8ae-4cd7-432d-b411-2af586df458b"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def neighborhood_model_tune(pdq, seasonal_pdq, neighborhood, df, df_grid_search):\n    best_ev = -1    \n    train = df[df['future'] == 0]\n    test = df[df['future'] == 1]\n    for param in pdq:\n        for param_seasonal in seasonal_pdq: \n            model = SARIMAX(train['ride_count_log'], order=param, seasonal_order=param_seasonal).fit(maxiter=1000, disp=False)\n            y_pred = model.forecast(steps = len(test))\n            ev = metrics.explained_variance_score(test['ride_count'], np.exp(y_pred))\n            if ev > best_ev:\n                best_ev = ev\n                best_order = param\n                best_s_order = param_seasonal\n                df_grid_search.loc[neighborhood,:] = [best_order, best_s_order, best_ev]\n    return df_grid_search"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d98ea5f9-4043-4f70-8277-174f597718a7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15729f06-42cd-4b51-a2d9-ed78ed4ddbce"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"utils_stats_modeling","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2575815718035563}},"nbformat":4,"nbformat_minor":0}
